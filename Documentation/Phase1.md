# Phase 1: Memory Management & Heap Allocator Implementation

**Status:** âœ… Complete  
**Chapters:** OSTEP 13-17 (Memory Virtualization & Free-Space Management)  
**Last Updated:** February 21, 2026

---

## Overview

Phase 1 establishes the **foundational memory management system** for the DDOS kernel. This phase implements a **Free List Allocator** that enables dynamic memory allocation, allowing Rust features like `Box`, `Vec`, and other heap-based data structures to function. Without this allocator, the kernel would only have stack memory and compile-time fixed-size data structures.

This is a **complete deep-dive** into the memory subsystem, covering architecture, algorithms, boilerplate code, and Rust fundamentals for OS development.

---

## ğŸ“ The Memory Folder Structure

```
src/memory/
â”œâ”€â”€ config.rs       â† Memory layout constants (addresses & sizes)
â”œâ”€â”€ heap.rs         â† Free List allocator implementation (300+ lines)
â”œâ”€â”€ mod.rs          â† Initialization boilerplate & GlobalAlloc trait
â””â”€â”€ README.md       â† This file (you can add one here for reference)
```

Each file has a specific, well-defined purpose. Let's look at each in detail.

---

## 1ï¸âƒ£ File: `src/memory/config.rs`

### Purpose
Define **memory layout constants** - the "map" of where everything lives in RAM.

### What It Contains

```rust
pub const KERNEL_START: usize = 0x80000;           // Where kernel code starts
pub const KERNEL_STACK_START: usize = 0x80000;    // Where stack begins
pub const HEAP_START: usize = KERNEL_STACK_START + 0x200000;  // 0x280000
pub const HEAP_SIZE: usize = 0x200000;             // 2 MB
```

### Understanding the Memory Layout

On a Raspberry Pi, the physical memory looks like this:

```
Memory Map (Physical Addresses)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

0x00000000  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  FIRMWARE/BOOTLOADER         â”‚  128 KB - 512 KB
            â”‚  (Created by Broadcom chip)  â”‚  We don't touch this!
            â”‚  Loads kernel at 0x80000     â”‚
0x00080000  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
            â”‚  KERNEL CODE + RODATA        â”‚  From boot.s and main.rs
            â”‚  (What we're running now)    â”‚
0x00200000  â”‚                              â”‚  (depends on kernel size)
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
0x00280000  â”‚  KERNEL STACK (2 MB)         â”‚  Stack grows DOWNWARD â¬‡ï¸
            â”‚  Currently using ~0.1 MB     â”‚  Grows from 0x280000 down
            â”‚  Room to grow to 0x80000      â”‚  to 0x80000
            â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
0x00480000  â”‚  HEAP (2 MB)                 â”‚  FreeList manages all of this
            â”‚  Currently: 1 region (free)  â”‚  Used by Box, Vec, etc.
            â”‚  As we allocate, splits into â”‚  with coalescing during free()
            â”‚  many smaller regions        â”‚
0x00680000  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
            â”‚  (Future: Device memory)     â”‚  Mailbox, HDMI framebuffer
            â”‚  (Future: Available RAM)     â”‚  SD card, NIC drivers
            â”‚                              â”‚
```

**Key Insight:** Stack and heap are separated by 2 MB, so they can't collide.

### Why These Specific Addresses?

1. **0x80000 (512 KB)**: Raspberry Pi bootloader convention
   - The ARM bootloader always loads kernels here
   - We don't have a choice - it's hardware/firmware defined
   
2. **Stack starts at 0x80000**: Grows downward
   - Stack grows from HIGH addresses to LOW addresses
   - Starting point: 0x80000
   - Growing downward: 0x7FFFF, 0x7FFFE, ...
   - Buffer: 2 MB of stack space = plenty of room

3. **Heap starts at 0x280000**: After stack buffer
   - 0x80000 + 0x200000 (2 MB) = 0x280000
   - Allocation goes UPWARD: 0x280000, 0x280001, 0x280002, ...
   - This way stack and heap can coexist

### The Formula

```
HEAP_START = KERNEL_STACK_START + KERNEL_STACK_SIZE
           = 0x80000 + 0x200000
           = 0x280000
```

This is not random - it's carefully designed to prevent stack/heap collision!

---

## 2ï¸âƒ£ File: `src/memory/heap.rs`

### Purpose
Implement the **FreeList allocator** - the heart of dynamic memory allocation.

This is ~300 lines of user-written code (yours!) implementing the algorithm from OSTEP Chapter 17.

### The Big Picture: What Does It Do?

```
Application: let vec = vec![1, 2, 3];
             â†“ (needs 24 bytes)
Rust runtime: Box::new(...) or Vec::new(...)
             â†“ (calls the allocator)
BestFit Allocator: "I'll give you a chunk from heap starting at 0x280100"
             â†“ (marks as used, returns pointer)
Application: vec contains 3 integers at 0x280100
```

### The Data Structures Explained

#### `FreeListNode` - Represents a Free Memory Region

```rust
pub struct FreeListNode {
    size: usize,                     // Total size of this free block (bytes)
    next: Option<*mut FreeListNode>, // Pointer to next free block
}
```

**Visual representation:**

```
In memory, a node looks like:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FreeListNode header    â”‚  (24 bytes on 64-bit)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Integer 1: size = 256  â”‚  (8 bytes) - how big is this free region?
â”‚ Integer 2: next ptr    â”‚  (8 bytes) - where's the next free region?
â”‚ Padding                â”‚  (8 bytes for alignment)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

Why? Because we need to track which memory regions are FREE. When you deallocate, we need to know "was the previous block also free? can I merge?"

#### `FreeList` - Manages All Free Regions

```rust
pub struct FreeList {
    pub head: Option<*mut FreeListNode>,   // Pointer to first free region
    pub start_address: usize,              // Where heap begins (0x280000)
    pub capacity: usize,                   // Total heap size (2 MB)
    pub heap_type: HeapType,               // Which algorithm to use
}
```

**Think of it as:**
- `head`: First node in a linked list of free regions
- `start_address`: "The heap starts here"
- `capacity`: "The heap is this big"
- `heap_type`: "Use this strategy to find free space"

### Initial State (Boot Time)

At startup, the entire 2 MB heap is one giant free region:

```
FreeList {
    head: Points to one FreeListNode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    start_address: 0x280000                        â”‚
    capacity: 0x200000 (2 MB)                      â”‚
    heap_type: BestFit                             â”‚
}                                                  â”‚
                                                   â†“
FreeListNode â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  size: 0x200000 (entire 2 MB is free!)
  next: None (there's only one node)
```

**This is the freest, most fragmented state possible** - but also the simplest!

### The 4 Free List Algorithms (OSTEP Chapter 17)

All solve the same problem: "Where in the free list should I allocate from?"

#### Algorithm #1: **FirstFit** âš¡ Fastest

```
Algorithm: Keep searching until you find ANY region big enough

    head â”€â”€â†’ [16 B] [8 B] [256 B] â† STOP HERE! 256 B is big enough
              skip   skip    use

Pros:
âœ… Fast - stops at first suitable region (O(1) typical case)
âœ… Simple to understand and implement
âœ… Good for small heaps with lots of activity

Cons:
âŒ Fragments at the START of list
âŒ Leaves many unusable tiny regions at beginning
âŒ Long-running systems degrade over time

Example of fragmentation:
After many allocs/deallocs:
[8B used][2B free][24B used][1B free][16B used]...
Request 100 B â†’ FAIL (no contiguous 100B free!)
```

Implementation in heap.rs:
```rust
fn find_region_first_fit(&mut self, requested_size: usize) 
    -> (Option<*mut FreeListNode>, Option<*mut FreeListNode>) 
{
    let mut current = self.head;
    while let Some(node_ptr) = current {
        if (*node_ptr).size >= requested_size {
            return (Some(node_ptr), prev);  // FOUND IT! Return now
        }
        prev = current;
        current = (*node_ptr).next;
    }
    (None, None)  // Couldn't find any suitable region
}
```

#### Algorithm #2: **BestFit** ğŸ¯ Balanced (Currently Selected)

```
Algorithm: Keep searching through ENTIRE list, find the SMALLEST region that fits

    head â”€â”€â†’ [256 B] [1000 B] [300 B]
               â†“        â†“        â†“
             OK       OK       â† BEST! (smallest that fits)
             
             (assume we request 250 B)

Pros:
âœ… Low external fragmentation - tight fits
âœ… Good memory utilization
âœ… Reasonable performance O(n) where n = free regions

Cons:
âŒ Slower than FirstFit
âŒ Still scans entire list
âŒ More splits = more nodes in free list later

Example of good behavior:
Request 100 B from: [256 B][1000 B][300 B]
Use 256 B region â†’ leaves [156 B] (not great)
Don't use 1000 B â†’ would leave [900 B] (wasteful!)
Better than FirstFit!
```

Implementation:
```rust
fn find_region_best_fit(&mut self, requested_size: usize) 
    -> (Option<*mut FreeListNode>, Option<*mut FreeListNode>) 
{
    let mut best: Option<*mut FreeListNode> = None;
    let mut best_prev = None;
    let mut current = self.head;
    
    // Search ENTIRE list
    while let Some(node_ptr) = current {
        if (*node_ptr).size >= requested_size {
            // This region is suitable
            // Is it smaller than what we found before? (BestFit criterion)
            if best.is_none() || (*node_ptr).size < (*best.unwrap()).size {
                best = Some(node_ptr);
                best_prev = prev;
            }
        }
        current = (*node_ptr).next;
    }
    (best, best_prev)
}
```

#### Algorithm #3: **WorstFit** âŒ Rarely Used

```
Algorithm: Find the LARGEST region >= requested_size

    head â”€â”€â†’ [256 B] [1000 B] [300 B]
               OK       â† USE THIS! (biggest)
             
             (assume we request 250 B)

Idea: "Use largest space, maybe this will create better divisions?"

Reality: Doesn't work well in practice.

Pros:
âœ… Keeps medium-sized regions around (theory)

Cons:
âŒ Actually causes MORE fragmentation (confirmed by research)
âŒ Wastes large regions on small allocations
âŒ Don't use this unless you have a specific reason

Example of why it's bad:
Free list: [256 B] [2000 B] [300 B]
Request 10 B
WorstFit chooses: 2000 B
Result: Leaves [1990 B free] but we just wasted a huge region!

BestFit would choose: 256 B
Result: Leaves [246 B free] and preserves the 2000 B for larger requests
```

#### Algorithm #4: **NextFit** ğŸ”„ Hybrid Approach

```
Algorithm: Like FirstFit, but remember where we last allocated and start there

    Allocation 1:
    head â”€â”€â†’ [A][B][C][D]
                â† allocate from B
             Remember position

    Allocation 2:
    head â”€â”€â†’ [A][B][C][D]
                 â†“
                Skip B (used), continue from C â† allocate from C
             Remember position
                 
    Allocation 3:
    head â”€â”€â†’ [A][B][C][D]
                       â†“
                   Skip D, wrap to A â† allocate from A
             Remember position

Pros:
âœ… Faster than BestFit (O(1) typical case)
âœ… Reduces clustering at start of list (better than FirstFit)
âœ… Good balance of speed and fragmentation

Cons:
âŒ More complex to implement
âŒ Requires maintaining state (last search position)

Use case: When you want speed like FirstFit but better fragmentation like BestFit
```

### Comparison Table

| Algorithm | Speed | Memory Use | Fragmentation | Notes |
|-----------|-------|-----------|---|---|
| FirstFit | O(1) avg | Poor | High | Fast but fragments at start |
| **BestFit** | O(n) | **Good** | **Low** | â­ Currently used - best for this OS |
| WorstFit | O(n) | Poor | High | Don't use (worse than BestFit) |
| NextFit | O(1) avg | Good | Low | Good hybrid (if you have time to implement) |

Here, **BestFit is selected** in `src/memory/mod.rs` because:
- The heap is only 2 MB
- We're not under extreme performance pressure
- Memory efficiency matters more than speed
- The kernel typically has low allocation churn

### Core Operations: Allocation

The allocate function is the main workhorse. Here's the step-by-step process:

```
User calls: let x = Box::new(42);
                    â†“
Rust calls: allocator.allocate(8)  // 8 bytes for a u32
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Step 1: Align the size               â”‚
            â”‚ requested = 8 bytes                  â”‚
            â”‚ aligned = (8 + 8 - 1) & ~(8-1)      â”‚
            â”‚        = 15 & ~7 = 8 bytes          â”‚
            â”‚ Why? Alignment helps CPU access     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Step 2: Add metadata overhead        â”‚
            â”‚ total = aligned + header + footer    â”‚
            â”‚       = 8 + 24 + 8 = 40 bytes       â”‚
            â”‚ Header (24B): size, next pointer    â”‚
            â”‚ Footer (8B): size for backward walk â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Step 3: Find suitable free region    â”‚
            â”‚ Find in free list using BestFit     â”‚
            â”‚ We have 1 region: 2 MB free        â”‚
            â”‚ Use it! (big enough)                â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Step 4: Check if we should split     â”‚
            â”‚ We request 40B from 2 MB            â”‚
            â”‚ Remaining: 2097152 - 40 = 2097112  â”‚
            â”‚ Split it!                           â”‚
            â”‚ â€¢ Keep 40 B for user (marked used)  â”‚
            â”‚ â€¢ Create new node for 2097112 B     â”‚
            â”‚ â€¢ Update free list pointers         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Step 5: Write metadata              â”‚
            â”‚ [Header][Data][Footer]              â”‚
            â”‚  â†“       â†“      â†“                    â”‚
            â”‚ size   user   size (for dealloc)    â”‚
            â”‚        data   lookup                â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
            Return pointer to user's data
            
Memory before:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ One big free region: 2 MB                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Memory after:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Used (40 B)    â”‚ Free (2 MB - 40 B)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  â†‘ pointer      â†‘
  returned       new node in free list
```

### Core Operations: Deallocation

When user frees memory, we need to "unborrow" it and return it to the free list:

```
User calls: drop(vec);  // Vector goes out of scope
                    â†“
Rust calls: allocator.deallocate(pointer)
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Step 1: Find the header             â”‚
            â”‚ User gives us pointer to data       â”‚
            â”‚ Header is 24 bytes BEFORE that      â”‚
            â”‚ header_ptr = data_ptr - 24          â”‚
            â”‚ Now we know: size, next pointer     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Step 2: Find insertion point        â”‚
            â”‚ Free list must stay SORTED by addr  â”‚
            â”‚ (important for coalescing!)         â”‚
            â”‚ Find where this block goes in order â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Step 3: Reinsert into free list     â”‚
            â”‚ Add this node back to the linked    â”‚
            â”‚ list in sorted order                â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Step 4: Forward Coalescing          â”‚
            â”‚ Is the NEXT block also free?        â”‚
            â”‚ If yes: merge them together         â”‚
            â”‚ "Join adjacent free regions"        â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Step 5: Backward Coalescing         â”‚
            â”‚ Is the PREVIOUS block also free?    â”‚
            â”‚ Use the footer to find previous     â”‚
            â”‚ Read footer 8 bytes BEFORE us       â”‚
            â”‚ If yes: merge them together         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Memory before deallocation:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Used   â”‚ Free (100B) â”‚ Used     â”‚ Free (500B)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Free this middle block:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Used   â”‚ Used (now)  â”‚ Used     â”‚ Free (500B)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â†‘ pointer to this block

After dealloc with coalescing:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Used   â”‚ Free (600B) â”‚â† Merged! â”‚ (empty)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Why merge? Prevents this nightmare scenario:
Without coalescing:
[1B used][1B free] [1B used][1B free] [1B used][1B free]...
Request 1000B â†’ FAIL! (no contiguous block)

With coalescing:
[1B used][1000B free! Merged from fragments]
Request 1000B â†’ SUCCESS!
```

### Memory Layout: How Data Actually Looks in RAM

When we allocate:

```
Allocate 16 bytes:
Requested:  16 B
Aligned:    16 B
Total block: 16 + 24 (header) + 8 (footer) = 48 B

Layout in memory:
0x280018 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚ FreeListNode (24 B):    â”‚
         â”‚  - size: 48             â”‚ â† Says "I'm a 48B block"
         â”‚  - next: 0x280080       â”‚ â† Points to next free region
0x280030 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ User's data (16 B):     â”‚
         â”‚ [0x0000000000000042]    â”‚ â† The actual integer 42 â† USER GETS POINTER HERE
         â”‚                         â”‚
0x280040 â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
         â”‚ Footer (8 B):           â”‚
         â”‚ [48]                    â”‚ â† "I'm a 48B block" (for dealloc backward walk)
0x280048 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

So when we:
1. Allocate: Return pointer to 0x280030 (the user's data start)
2. Deallocate: User passes 0x280030, we read back 24 bytes to get header at 0x280018
```

### Alignment Best Practices (Why ALIGN = 8?)

```rust
const ALIGN: usize = 8;  // 64-bit systems

Why 8 bytes?
- Pointers are 8 bytes, so align to 8
- A `usize` is 8 bytes, align to it
- Reduces fragmentation (every 8B boundary)
- Standard for 64-bit systems

Alignment formula:
align_up(size) = (size + ALIGN - 1) & !(ALIGN - 1)

Examples with ALIGN=8:
- align_up(1) = 8
- align_up(7) = 8
- align_up(8) = 8          (already aligned)
- align_up(9) = 16
- align_up(15) = 16
- align_up(16) = 16        (already aligned)

Binary view:
9 in binary:    1001
ALIGN-1 = 7:    0111
+ 7:            1 0000  = 16 in binary
```

### Fragmentation Explained

**External Fragmentation** - Free space is split into unusable pieces:

```
Without fragmentation:
[Used: 100B][Free: 1900B]
Request 1000B â†’ SUCCESS

WITH fragmentation:
[U:40][F:50][U:60][F:30][U:80][F:40]...
Request 1000B â†’ FAIL (no contiguous 1000B free!)

But total free = 50+30+40 = 120B
   (enough for 1000B? No!)
   
Coalescing fixes this:
[U:40][F:1000+][U:60]
Request 1000B â†’ SUCCESS!
```

---

## 3ï¸âƒ£ File: `src/memory/mod.rs`

### Purpose
"Boilerplate" initialization code that:
1. Creates the global allocator instance
2. Initializes it at boot time
3. Handles allocation failures

### Understanding the "Boilerplate"

**What does "boilerplate" mean?** Code that's necessary but mostly follows a pattern. You typically don't modify it much after initial setup.

### The Problem It Solves

In Rust, static variables must be **immutable**:

```rust
static MY_NUMBER: u32 = 42;
// All good, immutable, no problem

MY_NUMBER = 99;  // âŒ ERROR: Can't mutate a static!
```

But the allocator needs to **mutate** its internal state:

```rust
static ALLOCATOR: FreeList = ...;

ALLOCATOR.allocate(100);  // âŒ ERROR: allocate() takes &mut self
                          // but we can only provide &self (immutable)
```

**This is impossible in standard Rust!** That's where `Locked<T>` comes in.

### Solution: Interior Mutability with `Locked<T>`

See the next section for full details on `Locked<T>`.

### Global Allocator Registration

```rust
#[global_allocator]
static ALLOCATOR: Locked<FreeList> = Locked::new(FreeList {
    head: None,
    start_address: 0,
    capacity: 0,
    heap_type: HeapType::BestFit,
});
```

This attribute tells Rust:
- "This object is the allocator for Box, Vec, etc."
- ANY call to allocate memory goes through this object
- It must implement the `GlobalAlloc` trait (the allocate/deallocate interface)

### Why We Initialize with Dummy Values (0, 0, None)

We can't use real values (`HEAP_START`, `HEAP_SIZE`) in a `const` context. Const evaluation has a limited scope and can't access runtime values.

Solution: Initialize with dummy values, then "re-initialize" in the `init()` function:

```rust
static ALLOCATOR: Locked<FreeList> = Locked::new(FreeList {
    head: None,           // â† Dummy: "No regions"
    start_address: 0,     // â† Dummy: "Starts at 0"
    capacity: 0,          // â† Dummy: "Size is 0"
    heap_type: HeapType::BestFit,
});

// Later, during kernel boot:
pub fn init() {
    unsafe {
        let allocator = ALLOCATOR.lock();  // Get mutable access
        *allocator = FreeList::init(HEAP_START, HEAP_SIZE, HeapType::BestFit);
        // Now allocator has REAL values!
    }
}
```

Before `init()` is called: Allocator is "offline" (can't allocate anything)
After `init()` is called: Allocator is "online" (Box, Vec work!)

### The `init()` Function

```rust
pub fn init() {
    unsafe {
        let allocator = ALLOCATOR.lock();
        *allocator = FreeList::init(HEAP_START, HEAP_SIZE, HeapType::BestFit);
    }
}
```

**Step by step:**

1. `ALLOCATOR.lock()` - Get a mutable reference to the FreeList inside Locked<T>
2. `*allocator = ...` - Replace the entire FreeList struct with a real initialized one
3. `FreeList::init(...)` - Create a new FreeList pointing to real heap memory

**Why `unsafe`?**
- Modifying a global static requires `unsafe`
- It's safe because:
  - We only do it once (during boot)
  - No other code can call this simultaneously (single-threaded)
  - We're in kernel-only code (not reachable from userspace yet)

### The Allocation Error Handler

```rust
#[alloc_error_handler]
fn alloc_error_handler(layout: Layout) -> ! {
    panic!("allocation error: {:?}", layout)
}
```

This function is called when `Box::new()` or `Vec::new()` tries to allocate memory but **fails** (returns null).

**Why might it fail?**
- Requested size > HEAP_SIZE (impossible request)
- Heap is completely fragmented (no contiguous block available)
- HEAP_SIZE is too small for your workload

**What happens?**
- We can't recover (can't return `Result`, must return never type `!`)
- We panic with the layout that failed
- Kernel crashes with error message

**Production systems would:**
- Trigger garbage collection (we don't have one)
- Swap to disk (too complex for now)
- Terminate less important processes
- Just crash (what we do now - acceptable for a learning OS)

### Putting It All Together: Boot Sequence

```
1. KERNEL STARTS (src/cpu/boot.s)
   â†“
2. _main() is called (Rust main)
   â†“
3. memory::init() is called
   â”œâ”€ ALLOCATOR.lock() - get mutable access
   â”œâ”€ FreeList::init(0x280000, 0x200000, BestFit)
   â”‚  â””â”€ Write FreeListNode at 0x280000
   â””â”€ Now entire 2 MB heap is registered as ONE free region
   â†“
4. Console/UART drivers initialize
   â†“
5. Box::new() and Vec::new() NOW WORK!
   (Before this, any allocation would panic!)
```

---

## 4ï¸âƒ£ File: `src/utils/locked.rs`

### Purpose
Provide **interior mutability** for global allocator - allow mutation through immutable references.

### The Core Problem: Rust's Borrowing Rules

Rust's fundamental rule:

```
You can have:
âœ… Many immutable references (&T)
âœ… One mutable reference (&mut T)
âŒ NOT both at the same time
```

But the allocator is a **static** (always one reference):

```rust
// This is immutable!
static ALLOCATOR: FreeList = ...;

// Allocations need mutable access:
Box::new(42)  // âŒ Needs &mut ALLOCATOR but we only have &ALLOCATOR
```

### The Solution: `UnsafeCell`

`UnsafeCell` is a special Rust type that breaks this rule **safely** in certain cases:

```rust
pub struct Locked<A> {
    inner: UnsafeCell<A>,  // Can get mutable pointers from immutable refs
}
```

**How it works:**

```rust
impl<A> Locked<A> {
    pub fn lock(&self) -> &mut A {
        // self is immutable (&self)
        // But we return &mut A (mutable)!
        unsafe { &mut *self.inner.get() }
    }
}
```

This is "safe" (doesn't cause undefined behavior) IF:
- Only one thread accesses the data at a time
- We're careful not to hold multiple mutable references

### Why Is This Safe (For Our Kernel)?

In a **single-threaded** kernel:
- Only one CPU core runs code at any time
- Only one thread can call `lock()` simultaneously
- Therefore, no data races possible

**In a multi-threaded kernel**, this would be a race condition:

```
Thread 1: lock() â†’ &mut allocator â”€â”€â”€â”€â”€â†’ [allocate]
Thread 2: lock() â†’ &mut allocator â”€â”€â”€â”€â”€â†’ [allocate]
                     â†‘
                Same mutable ref!
                Both threads modify at once
                â†’ Data corruption!
```

That's why Chapter 28-29 (OSTEP) introduces **SpinLock**, which we'll implement in Phase 2:

```rust
// In Phase 2:
pub struct SpinLock<T> {
    inner: UnsafeCell<T>,
    locked: AtomicBool,  // â† Prevents simultaneous access!
}

impl<T> SpinLock<T> {
    pub fn lock(&self) -> &mut T {
        // Spin (busy wait) until locked bit is false
        while self.locked.compare_and_swap(false, true) {
            // Wait...
        }
        // Now we have exclusive access
        unsafe { &mut *self.inner.get() }
    }
}
```

### Memory Layout: UnsafeCell Under the Hood

```rust
UnsafeCell<T> is just a wrapper:

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UnsafeCell<A>          â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ inner: A         â”‚   â”‚ (contains the actual data)
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Example: UnsafeCell<FreeList>
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ UnsafeCell             â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ â”‚ FreeList {       â”‚   â”‚
â”‚ â”‚  head: Some(ptr) â”‚   â”‚
â”‚ â”‚  start: 0x280000 â”‚   â”‚
â”‚ â”‚  ...             â”‚   â”‚
â”‚ â”‚ }                â”‚   â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

When we call .lock():
Returns: mutable reference to the FreeList inside

```rust
let allocator = ALLOCATOR.lock();
*allocator = ...  // Modify the FreeList!
```
```

### Why the `Sync` Trait?

```rust
unsafe impl<A> Sync for Locked<A> {}
```

This tells Rust: "It's safe to send `Locked<A>` between threads."

Normally, types containing `UnsafeCell` are NOT `Sync` because they could cause data races. But we explicitly say "It's OK, we handle it correctly" by:

1. Implementing `Sync` manually with `unsafe impl`
2. Being responsible for correct synchronization (which we do via SpinLock in Phase 2)

### The Workflow in Boot

```
static ALLOCATOR: Locked<FreeList> = Locked::new(dummy_freelist);
                   â†‘
                   UnsafeCell inside

memory::init():
    let allocator = ALLOCATOR.lock();  // Get &mut FreeList
    *allocator = FreeList::init(...);  // Replace with real allocator
    // lock() returns, mutable reference dropped
    // Allocator now works!

Box::new(42):
    Rust calls: GlobalAlloc::alloc(&self, layout)
    Which calls: ALLOCATOR.lock().allocate(size)
    Which gets: &mut FreeList from UnsafeCell
    Which can: Mutate internal state safely (because single-threaded)
```

---

## ğŸ”— How It All Connects

### Initialization Flow

```
src/cpu/boot.s  (Assembly)
    â†“ Sets up stack, jumps to _main()
src/main.rs  (Rust entry point)
    â†“ Calls memory::init()
src/memory/mod.rs  (initialization)
    â†“ Calls FreeList::init() with values from config.rs
src/memory/config.rs  (HEAP_START, HEAP_SIZE)
    â†“ Returns initialized allocator
src/memory/heap.rs  (FreeList implementation)
    â†“ Now handles all allocations
src/utils/locked.rs  (Interior mutability)
    â†“ Wrapped the FreeList for static usage

Result: Box::new(), Vec::new() now work!
```

### When You Allocate Memory

```
Your code: let vec = vec![1, 2, 3];
    â†“
Rust macro: expands to Vec::new().push(1).push(2).push(3)
    â†“
Vec::new(): calls Box::new(capacity) for internal buffer
    â†“
Box::new(): calls allocator.alloc(Layout)
    â†“
GlobalAlloc impl: routes to ALLOCATOR
    â†“
Locked::lock(): gets &mut FreeList from UnsafeCell
    â†“
FreeList::allocate(): uses BestFit algorithm
    â†“
find_region_best_fit(): searches free list
    â†“
Returns pointer to free memory
    â†“
Vector's buffer is at that pointer!
```

### File Dependencies

```
mod.rs
    â”œâ”€â†’ depends on: config.rs, heap.rs, ../utils/locked.rs
    â””â”€â†’ uses: HEAP_START, HEAP_SIZE from config
    â””â”€â†’ uses: FreeList, HeapType from heap
    â””â”€â†’ uses: Locked<T> from utils

heap.rs
    â”œâ”€â†’ depends on: (none - core algorithms)
    â””â”€â†’ defines: FreeList, FreeListNode, HeapType, allocation algos

config.rs
    â”œâ”€â†’ depends on: (none - just constants)
    â””â”€â†’ defines: KERNEL_START, HEAP_START, HEAP_SIZE

locked.rs (in utils/)
    â”œâ”€â†’ depends on: (none - core Rust)
    â””â”€â†’ defines: Locked<T>, interior mutability wrapper
```

---

## ğŸ§  Rust Fundamentals for OS Development

### Concept 1: Raw Pointers vs Safe References

```rust
// Safe reference (Rust checks this)
let x = 42;
let r: &u32 = &x;  // Compiler verifies: x lives long enough

// Raw pointer (unsafe)
let ptr: *mut u32 = 0x280000 as *mut u32;  // Can point to anything!
// Compiler: "I don't know if this is valid!"

// Using raw pointer
unsafe {
    ptr.write(42);    // Write to raw address (anything could be there!)
    let value = ptr.read();  // Read from raw address
}
```

**Why kernel code needs unsafe:** Hardware registers are at fixed addresses, not allocated by Rust.

### Concept 2: Option<T> for Nullable Pointers

```rust
// In C:
void *node = NULL;  // Could be null
node->size = 100;   // Crash if null! â† undefined behavior

// In Rust:
let node: Option<*mut FreeListNode> = None;  // Explicitly nullable

if let Some(node_ptr) = node {
    // Safe: we know node_ptr is not null here
    unsafe { (*node_ptr).size = 100; }
} else {
    // Safe: handled the null case
}
// Can't forget to handle null! Compiler enforces it.
```

### Concept 3: `const fn` - Compile-Time Functions

```rust
pub const fn new(inner: A) -> Self {  // â† const fn
    Locked { inner: UnsafeCell::new(inner) }
}

// Can be used at compile time:
static ALLOCATOR: Locked<FreeList> = Locked::new(dummy);
                                     â†‘
                                     Called at compile time!
                                     No runtime cost
```

### Concept 4: `!` (Never Type) - Functions That Don't Return

```rust
fn alloc_error_handler(layout: Layout) -> ! {
    panic!("allocation error");  // â† Never returns!
}

// This means:
let x = alloc_error_handler(...);  // â† x can never be assigned
// Control flow exits (panics), x is never initialized
```

### Concept 5: Size and Alignment

```rust
size_of::<FreeListNode>() == 24  // On 64-bit systems
                                  // Field 1: usize (8)
                                  // Field 2: Option<*mut...> (8)
                                  // Padding: (8)

// Alignment:
// Every FreeListNode must start at an 8-byte boundary
// This is AUTOMATIC in Rust; compiler handles it
```

---

## ğŸ“Š Performance Characteristics

### Current Allocator (BestFit)

| Operation | Time Complexity | Best Case | Worst Case |
|-----------|-----------------|-----------|-----------|
| Allocate | O(n) | O(1) - free list sorted | O(n) - scan all regions |
| Deallocate | O(n) | O(1) - at end | O(n) - find insertion point |
| Coalesce | O(1) | Immediate | Immediate |

Where n = number of free regions

### Example Timeline

```
Time  Action               Free List
t0    Boot                 [2MB free]  (1 region)
t1    Alloc 100B           [100B used][2MB-100B free]  (2 regions)
t2    Alloc 50B            [100B][50B][2MB-150B]  (3 regions)
t3    Free first 100B      [100B][50B][2MB-150B]  (3)
      (coalesce)           [150B][2MB-150B]  (2)
t4    Alloc 200B           [200B][2MB-350B]  (2)
```

As the OS runs, n (number of free regions) typically grows from 1 to ~10-40, then stabilizes. Most allocations are O(1-2) after initial fragmentation.

---

## ğŸ“ Learning Outcomes

After Phase 1, you understand:

âœ… **Memory Layout**: How addresses are organized on RPi  
âœ… **Free List Algorithm**: The core of malloc/free  
âœ… **Allocation Strategies**: First/Best/Worst/NextFit tradeoffs  
âœ… **Fragmentation**: External fragmentation and coalescing  
âœ… **Rust Pointers**: Raw pointers, UnsafeCell, interior mutability  
âœ… **Global Allocator**: How Rust redirects all allocations  
âœ… **Boilerplate Code**: Why it's there and what it does  
âœ… **Metadata**: Headers and footers for allocation bookkeeping  

---

## ğŸš€ Building & Running

### Quick Start - Using Scripts

```bash
# Build and run in QEMU
./scripts/build-qemu.sh

# Build for real RPi4 hardware
./scripts/build-rpi4.sh
```

### Manual Build

```bash
# QEMU (default)
cargo build --target aarch64-unknown-none-softfloat

# Or explicit feature
cargo build --features qemu --target aarch64-unknown-none-softfloat

# RPi4
cargo build --no-default-features --features rpi4 \
  --target aarch64-unknown-none-softfloat

# Run in QEMU
qemu-system-aarch64 -M raspi3b -serial stdio \
  -kernel target/aarch64-unknown-none-softfloat/debug/ddos
```

### Expected Output

```
[KERNEL] Booting DDOS...
[KERNEL] Heap Initialized. (BestFit)
[KERNEL] Console initialized via HDMI
Testing Heap Allocation...
  âœ“ Box allocated: 42
  âœ“ Vec allocated: [0, 1, 2, 3, 4]
  âœ“ String allocated: "Hello, Heap!"
>
```

---

## ğŸ“– OSTEP References

| Chapter | Title | Relevance to Phase 1 |
|---------|-------|---|
| 13 | The Abstraction: Address Spaces | Memory layout, kernel vs user space |
| 14 | Interlude: Memory API | malloc/free interface design |
| 15 | Mechanism: Address Translation | Virtual to physical address mapping |
| 16 | Segmentation | Hardware memory protection (skipped - ARM uses paging) |
| 17 | Free-Space Management | â­ **Core of this phase** - all allocation algorithms |

### Key Concepts from Ch. 17

- Free list as linked list of free regions
- Allocation strategies (First/Best/Worst/NextFit)
- Block splitting (allocate part of a region)
- Coalescing (merge adjacent free regions)
- Headers and footers for metadata
- External vs internal fragmentation

---

## ğŸ”® What's Next: Phase 2

**Concurrency & Synchronization** (OSTEP Chapters 26-29)

Currently, each function can mutate the allocator. In Phase 2:

1. Implement **SpinLock<T>** - prevents simultaneous access
2. Wrap Console in SpinLock - multiple "threads" can't write simultaneously
3. Wrap UART in SpinLock - kernel and drivers won't fight over output
4. Theory: Race conditions, deadlocks, synchronization

This moves `Locked<T>` from "single-threaded hack" to proper "multi-threaded primitive."

---

## Summary

âœ… **Complete Free List allocator** with 4 selectable strategies  
âœ… **BestFit algorithm** selected for memory efficiency  
âœ… **Block splitting & coalescing** prevents fragmentation  
âœ… **GlobalAlloc integration** - Box and Vec work!  
âœ… **Memory layout** carefully designed (stack â‰  heap)  
âœ… **Hardware abstraction** - runs on QEMU, RPi3, RPi4  
âœ… **Interior mutability** - static allocator can be mutated safely  
âœ… **Boilerplate code** - necessary for Rust integration  

The kernel can now use any Rust heap collection!

---

**Author:** Daksh Desai (user-implemented: config.rs, heap.rs, hardwareselect.rs, build scripts)  
**Date:** February 21, 2026  
**Status:** âœ… Phase 1 Complete
